optimizer:
  name: Adam
  lr: 5e-4
  betas: [0.9, 0.999]
training:
  batch_size: 128
  num_epochs: 128
data:
  num_workers: 4
  augmentations: 
    RandomHorizontalFlip:
      p: 0.5
    RandomVerticalFlip:
      p: 0.5
model:
  ddpm:
    betas: [1e-4, 0.02]
    num_timesteps: 1000
  unet:
    in_channels: 3
    out_channels: 3
    hidden_size: 128
logger:
  enable_logging: True