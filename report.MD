# Исправление ошибок
* Сперва я исправлял ошибки, пока **main.py** не смог успешно запуститься и отработать хотя бы эпоху:
  1. Баг 1: Модель падает из-за различия в девайсах (CUDA и CPU). Смотрим где падение, и легко видно что дело в timestep, который забыли перевести на device.
  2. Баг 2: CUDA падает по памяти. Ищем место падения — upblock в юнете. Слой выглядит правильным, а значит беда во входном тензоре. Смотрим на шейпы thro, temb и их суммы и находим ошибку в бродкастинге. 
  3. Баг 3: Снова разные device'ы, на этот раз в семплировании. Легко их исправляем (и за одно создаём папку для семплов, если её не было).

* Затем я попытался прогнать имеющиеся тесты:
  1. test_diffusion работает только иногда. Зафиксируем сид и установим use_deterministic_algorithms (обязательно в самом начале, т.к. модель тоже инициализируется случайно). Для теста на CPU этого должно быть достаточно, после этого тест прошёл 20 раз подряд.
  2. Баг 4: test_train_on_one_batch не работает. Тут я просто очень долго копался абсолютно во всех файлах кода. К моему величайшему разочарованию ошибка была в математике. По-моему добавлять такие баги это просто низко.

Все найденные баги я отметил комментарием вида `# FIX: ...`.

# Integration test
...

# Логгирование в wandb и рефакторинг кода
* Я добавил небольшой рефакторинг для поддержки конфигов *hydra* и логгирования в *wandb*. 
* Большая часть изменений находится в **main.py** и касается обработки конфига и логгирования.
* В **train.py** есть только небольшие изменения для логгирования. 
* Я также добавил поддержку расписаний lr, но оставил только константный lr. 
* В целом код довольно понятный, где надо я оставлял комментарии, в дальнейшем комментировать нет смысла.
* Я логгировал гиперпараметры в wandb указывая словарь параметром *config* в *init*'е; а также логгируя сам .yaml файл конфига (config в артефактах).
* Ссылка на проект wandb: https://wandb.ai/dlishudi/EDL-HW2

# Конфиги hydra
* Папка с конфигами — conf.
* Конфиги для обучения лежат в папке train. Для более серьёзных проектов имеет смысл также отдельно хранить конфиги и для других этапов.
* Далее они разделены на конфиги dataloader'а, логгера, модели, оптимизатора, расписания lr и самого процесса обучения.
* Я немного оверкиллнул разбиение на модули, по факту же различные подфайлы есть только у dataloader'а (добавлены аугментации) и оптимизатора (Adam/SGD).
* В дополнительном запуске я изменил оптимизатор с Adam'а на SGD с параметрами *lr=1e-4, momentum: 0.9*. Я хотел также добавить аугментации, но забыл; а перепрогнать обучения не успел (но они работают!).

# Как запускать код
* В идеале — запускать через `dvc exp run` или `dvc repro`, он прочтёт **conf/config.yaml**, построит **params.yaml** и запустит всё сам.
  * Проще всего изменить конфигурацию можно явно поменяв файл конфига .
  * Альтернативно можно подать dvc аргументы `-S ...`, чтобы изменить оригинальный конфиг. Например `dvc exp run -S "train/optimizer=sgd" -S "train/dataloader=augmented"`.
* Если хочется запустить **main.py** без *dvc* (и params.yaml нет, или они отстали по версии), то можно указать ему желаемый конфиг с помощью `python3 main.py --config-path=conf --config-name=config.yaml`.
  * Аналогично можно изменить конфиг дефолтными штучками гидры вроде ++.
